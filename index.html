<!DOCTYPE html>
<html xmlns:th="http://www.thymeleaf.org">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Camera Feed Modal</title>
    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        #video {
            width: 100%;
            height: 100%;
            object-fit: cover;
        }

        .modal-content {
            height: 650px;
        }

        #overlay {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: 2;
            pointer-events: none;
            /* Prevent interactions with the canvas */
        }
    </style>
</head>

<body>

    <div class="container text-center" style="margin-top: 20%;">
        <select id="cameraSelect" class="form-select mb-3" aria-label="Camera Select" style="display: none;">
            <option value="environment">Back Camera</option>
            <option value="user">Front Camera</option>
        </select>
        <button id="openCameraBtn" class="btn btn-primary" data-bs-toggle="modal" data-bs-target="#cameraModal"
            disabled>
            Open Camera
        </button>
        <p id="loadingStatus">Loading models...</p>
    </div>

    <!-- Modal -->
    <div class="modal fade" id="cameraModal" tabindex="-1" aria-labelledby="cameraModalLabel" aria-hidden="true">
        <div class="modal-dialog modal-dialog-centered">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title" id="cameraModalLabel">Camera Feed</h5>
                    <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body" style="position: relative; padding: 0px;">
                    <video id="video" autoplay></video>
                    <canvas id="overlay"></canvas>
                </div>
            </div>
        </div>
    </div>

    <!-- Bootstrap JS with Popper.js -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
    <script src="./face-api.min.js"></script> <!-- Ensure this path is correct -->
    <script>

        const video = document.getElementById('video');
        const overlay = document.getElementById('overlay');
        const context = overlay.getContext('2d');
        const openCameraBtn = document.getElementById('openCameraBtn');
        const loadingStatus = document.getElementById('loadingStatus');
        const cameraSelect = document.getElementById('cameraSelect');

        async function loadModels() {
            try {
                console.log("Loading models...");
                // Log each model loading step
                await faceapi.nets.tinyFaceDetector.loadFromUri('./models');
                console.log("tinyFaceDetector model loaded.");

                await faceapi.nets.faceLandmark68Net.loadFromUri('./models');
                console.log("faceLandmark68Net model loaded.");

                openCameraBtn.disabled = false; // Enable the button once models are loaded
                loadingStatus.textContent = 'Models loaded. You can now open the camera!';
            } catch (error) {
                loadingStatus.textContent = 'Error loading models. Check your paths.';
                console.error("Error loading models:", error);
            }
        }

        function isMobileDevice() {
            return /Mobi|Android/i.test(navigator.userAgent); // Basic mobile detection
        }
        var faceDetectionInterval;

        function startCamera() {

            const selectedCamera = isMobileDevice() ? cameraSelect.value : 'environment'; // Default to back camera for non-mobile
            const constraints = {
                video: {
                    facingMode: selectedCamera
                }
            };

            if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
                navigator.mediaDevices.getUserMedia(constraints)
                    .then(function (stream) {
                        video.srcObject = stream;
                        video.play();
                        console.log("Camera started.");

                        // Dynamically adjust canvas size to match video
                        video.onloadedmetadata = () => {
                            overlay.width = video.videoWidth;
                            overlay.height = video.videoHeight;

                            // Start face detection loop
                            faceDetectionInterval = setInterval(detectSingleFace, 200);
                        };
                    })
                    .catch(function (error) {
                        console.error("Error accessing camera:", error);
                    });
            } else {
                console.error("Browser does not support camera access.");
            }
        }

        async function detectSingleFace() {
            try {
                // Detect a single face using face-api.js
                const detection = await faceapi.detectSingleFace(video, new faceapi.TinyFaceDetectorOptions());

                if (detection && detection.box) {
                    const box = detection.box; // Get the bounding box of the detected face
                    const faceCenterX = box.x + box.width / 2;
                    const faceCenterY = box.y + box.height / 2;

                    // Check if the face is inside the elliptical guider
                    const isFaceInside = isFaceInGuider(faceCenterX, faceCenterY, box.width, box.height);
                    drawFaceGuider(isFaceInside);
                } else {
                    // No face detected, keep the guider red
                    drawFaceGuider(false);
                }
            } catch (error) {
                console.error("Error in face detection:", error);
            }
        }

        // Function to check if the face is inside the guider
        function isFaceInGuider(faceCenterX, faceCenterY, faceWidth, faceHeight) {
            // Guider dimensions based on video size
            const guideHeightPercentage = (window.innerWidth <= 460) ? 0.3 : 0.55;
            const guideWidthPercentage = (window.innerWidth <= 460) ? 0.3 : 0.35;

            const guideHeight = video.videoHeight * guideHeightPercentage;
            const guideWidth = video.videoWidth * guideWidthPercentage;
            const guideX = video.videoWidth / 2;
            const guideY = video.videoHeight / 2;

            // Calculate the horizontal and vertical radii of the ellipse
            const radiusX = guideWidth / 2;
            const radiusY = guideHeight / 2;

            // Check if the face's center is within the ellipse's radii
            const normalizedX = (faceCenterX - guideX) / radiusX;
            const normalizedY = (faceCenterY - guideY) / radiusY;

            // If the normalized X and Y distances are within 1, the face is inside the ellipse
            return (normalizedX ** 2 + normalizedY ** 2) <= 1;
        }

        function drawFaceGuider(isFaceInside) {
            // Clear the canvas before redrawing
            context.clearRect(0, 0, overlay.width, overlay.height);

            // Set the color of the ellipse based on whether the face is detected
            const guideLineColor = isFaceInside ? '#00FF00' : 'red';

            // Set guide dimensions as a percentage of the video size
            const guideHeightPercentage = (window.innerWidth <= 460) ? 0.3 : 0.55;
            const guideWidthPercentage = (window.innerWidth <= 460) ? 0.3 : 0.35;

            const guideHeight = video.videoHeight * guideHeightPercentage;
            const guideWidth = video.videoWidth * guideWidthPercentage;
            const guideX = video.videoWidth / 2;
            const guideY = video.videoHeight / 2;

            // Set the stroke style and line width for the guider
            context.strokeStyle = guideLineColor;
            context.lineWidth = 3;

            // Draw the ellipse
            context.beginPath();
            context.ellipse(guideX, guideY, guideWidth / 1.3, guideHeight / 1.75, 0, 0, 2 * Math.PI);
            context.stroke();
        }

        if (isMobileDevice()) {
            cameraSelect.style.display = 'block'; // Show the dropdown for mobile devices
        }

        loadModels();

        document.getElementById('cameraModal').addEventListener('shown.bs.modal', startCamera);

        document.getElementById('cameraModal').addEventListener('hidden.bs.modal', function () {
            const stream = video.srcObject;
            const tracks = stream.getTracks();
            tracks.forEach(track => track.stop());
            video.srcObject = null;
            clearInterval(faceDetectionInterval);
        });
    </script>

</body>

</html>