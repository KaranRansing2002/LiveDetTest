<!DOCTYPE html>
<html xmlns:th="http://www.thymeleaf.org">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Camera Feed Modal</title>
    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        #video {
            width: 100%;
            height: 100%;
            object-fit: cover;
        }

        .modal-dialog {
            max-width: 100%;
            width: 100%;
            height: 100%;
            margin: 0;
            display: flex;
            justify-content: center;
        }

        .modal-content {
            width: 550px;
            height: 720px;
            border-radius: 0;
            overflow: hidden;
        }

        #overlay {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: 2;
            pointer-events: none;
            /* Prevent interactions with the canvas */
        }
    </style>
</head>

<body>

    <div class="container text-center" style="margin-top: 20%;">
        <select id="cameraSelect" class="form-select mb-3" aria-label="Camera Select" style="display: none;">
            <option value="environment">Back Camera</option>
            <option value="user">Front Camera</option>
        </select>
        motion parallax
        <button id="openCameraBtn" class="btn btn-primary" data-bs-toggle="modal" data-bs-target="#cameraModal"
            disabled>
            Open Camera
        </button>
        <p id="loadingStatus">Loading models...</p>
    </div>

    <div>
        <img style="border:2px solid red;" id="myimage" src="" />
    </div>
    <!-- Modal -->
    <div class="modal fade" id="cameraModal" tabindex="-1" aria-labelledby="cameraModalLabel" aria-hidden="true"
        style="padding: 0;">
        <div class="modal-dialog modal-dialog-centered">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title" id="cameraModalLabel">Camera Feed</h5>
                    <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body" style="position: relative; padding: 0px;">
                    <video id="video" autoplay></video>
                    <canvas id="overlay"></canvas>
                </div>
            </div>
        </div>
    </div>

    <!-- Bootstrap JS with Popper.js -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
    <script src="./face-api.min.js"></script> <!-- Ensure this path is correct -->
    <script>

        const video = document.getElementById('video');
        const overlay = document.getElementById('overlay');
        const context = overlay.getContext('2d');
        const openCameraBtn = document.getElementById('openCameraBtn');
        const loadingStatus = document.getElementById('loadingStatus');
        const cameraSelect = document.getElementById('cameraSelect');
        const myimage = document.getElementById('myimage');

        async function loadModels() {
            try {
                console.log("Loading models...");
                // Log each model loading step
                await faceapi.nets.tinyFaceDetector.loadFromUri('./models');
                console.log("tinyFaceDetector model loaded.");

                await faceapi.nets.faceLandmark68Net.loadFromUri('./models');
                console.log("faceLandmark68Net model loaded.");

                openCameraBtn.disabled = false; // Enable the button once models are loaded
                loadingStatus.textContent = 'Models loaded. You can now open the camera!';
            } catch (error) {
                loadingStatus.textContent = 'Error loading models. Check your paths.';
                console.error("Error loading models:", error);
            }
        }

        function isMobileDevice() {
            return /Mobi|Android/i.test(navigator.userAgent); // Basic mobile detection
        }
        var faceDetectionInterval;

        function startCamera() {

            const selectedCamera = isMobileDevice() ? cameraSelect.value : 'environment'; // Default to back camera for non-mobile
            const constraints = {
                video: {
                    width: 1280,
                    height: 960,
                    facingMode: selectedCamera,
                }
            };

            if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
                navigator.mediaDevices.getUserMedia(constraints)
                    .then(function (stream) {
                        video.srcObject = stream;
                        video.play();
                        console.log("Camera started.");

                        //checking the camera actual height and width
                        const videoTrack = stream.getVideoTracks()[0];
                        const settings = videoTrack.getSettings();
                        const cameraWidth = settings.width;
                        const cameraHeight = settings.height;
                        console.log(`Camera resolution: ${cameraWidth}x${cameraHeight}`);


                        // Dynamically adjust canvas size to match video
                        video.onloadedmetadata = () => {
                            overlay.width = video.videoWidth;
                            overlay.height = video.videoHeight;

                            // Start face detection loop
                            faceDetectionInterval = setInterval(detectSingleFace, 200);
                        };
                    })
                    .catch(function (error) {
                        console.error("Error accessing camera:", error);
                    });
            } else {
                console.error("Browser does not support camera access.");
            }
        }

        async function detectSingleFace() {
            try {
                // Detect a single face with landmarks
                let detection = await faceapi.detectSingleFace(video, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks();

                if (detection && detection.landmarks) {
                    const box = detection.alignedRect.box; // Bounding box of the detected face
                    const essentialLandmarks = getEssentialLandmarks(detection.landmarks);

                    // Check if all essential landmarks are inside the guider
                    const areLandmarksInside = essentialLandmarks.every(({ name, position }) => {
                        const isInside = isPointInGuider(position.x, position.y);
                        if (!isInside) {
                            console.log(`Outside guider: ${name} at (${position.x}, ${position.y})`);
                        }
                        return isInside;
                    });

                    // Check if face covers more than 70% of the guider
                    const doesFaceCoverGuider = doesFaceCoverEnough(box);

                    // Draw guider based on both conditions
                    const isFaceValid = areLandmarksInside && doesFaceCoverGuider;
                    drawFaceGuider(isFaceValid);

                    if (isFaceValid) {
                        console.log(video.videoHeight, video.videoWidth);
                    }
                } else {
                    drawFaceGuider(false);
                }
            } catch (error) {
                console.error("Error in face detection:", error);
            }
        }

        // Helper to get essential landmarks
        function getEssentialLandmarks(landmarks) {
            return [
                { name: 'leftEye', position: landmarks.getLeftEye()[0] },
                { name: 'rightEye', position: landmarks.getRightEye()[0] },
                { name: 'nose', position: landmarks.getNose()[0] },
                { name: 'mouth', position: landmarks.getMouth()[0] }
            ];
        }

        // Function to check if a point is within the face guider's bounds
        function isPointInGuider(x, y, box) {
            const guideHeightPercentage = (window.innerWidth <= 460) ? 0.3 : 0.55;
            const guideWidthPercentage = (window.innerWidth <= 460) ? 0.3 : 0.35;

            const guideHeight = video.videoHeight * guideHeightPercentage;
            const guideWidth = video.videoWidth * guideWidthPercentage;
            const guideX = video.videoWidth / 2;
            const guideY = video.videoHeight / 2;

            const radiusX = guideWidth / 2;
            const radiusY = guideHeight / 2;

            const normalizedX = (x - guideX) / radiusX;
            const normalizedY = (y - guideY) / radiusY;

            return (normalizedX ** 2 + normalizedY ** 2) <= 1;
        }

        function doesFaceCoverEnough(box) {
            const guideHeightPercentage = (window.innerWidth <= 460) ? 0.3 : 0.55;
            const guideWidthPercentage = (window.innerWidth <= 460) ? 0.3 : 0.35;

            const guideHeight = video.videoHeight * guideHeightPercentage;
            const guideWidth = video.videoWidth * guideWidthPercentage;

            const faceArea = box.width * box.height;
            const guiderArea = guideWidth * guideHeight;

            return faceArea >= guiderArea * 0.6; // 70% threshold
        }

        // Function to draw the face guider
        function drawFaceGuider(isAllInGuider) {
            context.clearRect(0, 0, overlay.width, overlay.height);
            const guideLineColor = isAllInGuider ? '#00FF00' : 'red';

            const guideHeightPercentage = (window.innerWidth <= 460) ? 0.3 : 0.55;
            const guideWidthPercentage = (window.innerWidth <= 460) ? 0.3 : 0.35;

            const guideHeight = video.videoHeight * guideHeightPercentage;
            const guideWidth = video.videoWidth * guideWidthPercentage;
            const guideX = video.videoWidth / 2;
            const guideY = video.videoHeight / 2;

            context.strokeStyle = guideLineColor;
            context.lineWidth = 3;
            context.beginPath();
            context.ellipse(guideX, guideY, guideWidth / 1.3, guideHeight / 1.75, 0, 0, 2 * Math.PI);
            context.stroke();
        }

        function captureImageAtCameraResolution() {
            //Ensure video has loaded and has resolution data
            // if (video.videoWidth && video.videoHeight) {
            //     // Set canvas dimensions to match video (camera's native resolution)
            //     const canvas = document.createElement('canvas');
            //     canvas.width = video.videoWidth;
            //     canvas.height = video.videoHeight;

            //     // Draw the current frame from the video onto the canvas
            //     const ctx = canvas.getContext('2d');
            //     ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

            //     // Get the image data URL (in full camera resolution)
            //     const imageDataUrl = canvas.toDataURL('image/png');
            //     //console.log("Captured Image URL:", imageDataUrl);

            //     // You can now use the imageDataUrl as needed
            //     myimage.src = imageDataUrl;
            //     return imageDataUrl;
            // } else {
            //     console.warn("Video is not ready for capturing yet.");
            //     return null;
            // }

            if (video.videoWidth && video.videoHeight) {
                myimage.src=captureAndResizeImage(video);
            } else {
                console.warn("Video is not ready for capturing yet.");
                return null;
            }
        }

        function captureAndResizeImage(videoElement, targetWidth = 550, targetHeight = 780) {
            // Step 1: Create a canvas at the camera's maximum resolution
            const maxWidth = videoElement.videoWidth;
            const maxHeight = videoElement.videoHeight;
            const highResCanvas = document.createElement("canvas");
            highResCanvas.width = maxWidth;
            highResCanvas.height = maxHeight;
            const highResCtx = highResCanvas.getContext("2d");

            // Draw the video frame onto the high-resolution canvas
            highResCtx.drawImage(videoElement, 0, 0, maxWidth, maxHeight);

            // Step 2: Create another canvas for resizing the image to target dimensions
            const targetCanvas = document.createElement("canvas");
            targetCanvas.width = targetWidth;
            targetCanvas.height = targetHeight;
            const targetCtx = targetCanvas.getContext("2d");

            // Calculate aspect ratios
            const sourceAspectRatio = maxWidth / maxHeight;
            const targetAspectRatio = targetWidth / targetHeight;

            let renderWidth, renderHeight, offsetX = 0, offsetY = 0;

            // Determine the dimensions to draw the high-res image onto the target canvas
            if (sourceAspectRatio > targetAspectRatio) {
                // Image is wider than target, crop width
                renderHeight = targetHeight;
                renderWidth = targetHeight * sourceAspectRatio;
                offsetX = (renderWidth - targetWidth) / 2;
            } else {
                // Image is taller than target, crop height
                renderWidth = targetWidth;
                renderHeight = targetWidth / sourceAspectRatio;
                offsetY = (renderHeight - targetHeight) / 2;
            }

            // Step 3: Draw the high-resolution image onto the target canvas with resizing
            targetCtx.drawImage(highResCanvas, -offsetX, -offsetY, renderWidth, renderHeight);

            // Step 4: Get the resized image as a data URL or Blob
            const resizedImageDataUrl = targetCanvas.toDataURL("image/png");  // Can also use .toBlob

            // Display or download the image as needed
            //console.log("Resized Image Data URL:", resizedImageDataUrl);
            return resizedImageDataUrl;
        }



        if (isMobileDevice()) {
            cameraSelect.style.display = 'block'; // Show the dropdown for mobile devices
        }

        loadModels();

        document.getElementById('cameraModal').addEventListener('shown.bs.modal', startCamera);

        document.getElementById('cameraModal').addEventListener('hidden.bs.modal', function () {
            captureImageAtCameraResolution();
            const stream = video.srcObject;
            const tracks = stream.getTracks();
            tracks.forEach(track => track.stop());
            video.srcObject = null;
            clearInterval(faceDetectionInterval);
        });

        async function startCameraAndLogResolution() {
            const video = document.createElement('video');

            try {
                // Request access to the user's camera
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video.srcObject = stream;

                // Wait for the video metadata to load, which includes resolution data
                await new Promise((resolve) => {
                    video.onloadedmetadata = () => {
                        resolve();
                    };
                });

                // Get the actual resolution of the camera
                const cameraWidth = video.videoWidth;
                const cameraHeight = video.videoHeight;

                console.log(`Camera resolution: ${cameraWidth} x ${cameraHeight}`);

                // Start playing the video
                video.play();

                // Optionally, add video to the document or use as needed
                document.body.appendChild(video);
            } catch (error) {
                console.error("Error accessing the camera:", error);
            }
        }

    </script>

</body>

</html>